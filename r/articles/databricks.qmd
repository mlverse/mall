---
title: "Databricks"
execute:
  eval: true
  freeze: true
---

```{r}
#| include: false
source("../utils/knitr-print.R")
```

```{r, include = FALSE}
packageStartupMessage(library(dplyr))
```

This brief example shows how seamless it is to use the same functions,
but against a remote database connection. Today, it works with the following
functions:

- `llm_sentiment()`
- `llm_summarize()`
- `llm_classify()`

## Examples

We will start by connecting to the Databricks Warehouse

```{r}
library(mall)
library(DBI)

con <- dbConnect(
  odbc::databricks(),
  HTTPPath = Sys.getenv("DATABRICKS_PATH")
)
```

Next, we will create a small reviews table

```{r}
library(dplyr)

reviews <- tribble(
  ~review,
  "This has been the best TV I've ever used. Great screen, and sound.",
  "I regret buying this laptop. It is too slow and the keyboard is too noisy",
  "Not sure how to feel about my new washing machine. Great color, but hard to figure"
)

tbl_reviews <- copy_to(con, reviews, overwrite = TRUE)
```

Using `llm_sentiment()` in Databricks will call that vendor's SQL AI function
directly:

```{r}
tbl_reviews |>
  llm_sentiment(review)
```

There are some differences in the arguments, and output of the LLM's. Notice
that instead of "neutral", the prediction is "mixed".  The AI Sentiment function
does not allow to change the possible options.

Next, we will try `llm_summarize()`. The `max_words` argument maps to the same
argument in the AI Summarize function:

```{r}
tbl_reviews |>
  llm_summarize(review, max_words = 5) |>
  show_query()
```

`llm_classify()` for this back-end, will only accept unnamed options. 

```{r}
tbl_reviews |>
  llm_classify(review, c("appliance", "computer"))
```


