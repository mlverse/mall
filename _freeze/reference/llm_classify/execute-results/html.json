{
  "hash": "6356bfadb40ae97144a86bcf60c1aa38",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Categorize data as one of options given\"\nexecute:\n  eval: true\n  freeze: true\n---\n\n\n\n[R/llm-classify.R](https://github.com/mlverse/mall/blob/main/r/R/llm-classify.R)\n\n## llm_classify\n\n## Description\n Use a Large Language Model (LLM) to classify the provided text as one of the options provided via the `labels` argument. \n\n\n## Usage\n```r\n \nllm_classify( \n  .data, \n  col, \n  labels, \n  pred_name = \".classify\", \n  additional_prompt = \"\" \n) \n \nllm_vec_classify(x, labels, additional_prompt = \"\", preview = FALSE) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| .data | A `data.frame` or `tbl` object that contains the text to be analyzed |\n| col | The name of the field to analyze, supports `tidy-eval` |\n| labels | A character vector with at least 2 labels to classify the text as |\n| pred_name | A character vector with the name of the new column where the prediction will be placed |\n| additional_prompt | Inserts this text into the prompt sent to the LLM |\n| x | A vector that contains the text to be analyzed |\n| preview | It returns the R call that would have been used to run the prediction. It only returns the first record in `x`. Defaults to `FALSE` Applies to vector function only. |\n\n\n\n## Value\n `llm_classify` returns a `data.frame` or `tbl` object. `llm_vec_classify` returns a vector that is the same length as `x`. \n\n\n## Examples\n\n::: {.cell}\n\n```{.r .cell-code}\n \n \nlibrary(mall) \n \ndata(\"reviews\") \n \nllm_use(\"ollama\", \"llama3.2\", seed = 100, .silent = TRUE) \n \nllm_classify(reviews, review, c(\"appliance\", \"computer\")) \n#> # A tibble: 3 × 2\n#>   review                                        .classify\n#>   <chr>                                         <chr>    \n#> 1 This has been the best TV I've ever used. Gr… computer \n#> 2 I regret buying this laptop. It is too slow … computer \n#> 3 Not sure how to feel about my new washing ma… appliance\n \n# Use 'pred_name' to customize the new column's name \nllm_classify( \n  reviews, \n  review, \n  c(\"appliance\", \"computer\"), \n  pred_name = \"prod_type\" \n) \n#> # A tibble: 3 × 2\n#>   review                                        prod_type\n#>   <chr>                                         <chr>    \n#> 1 This has been the best TV I've ever used. Gr… computer \n#> 2 I regret buying this laptop. It is too slow … computer \n#> 3 Not sure how to feel about my new washing ma… appliance\n \n# Pass custom values for each classification \nllm_classify(reviews, review, c(\"appliance\" ~ 1, \"computer\" ~ 2)) \n#> # A tibble: 3 × 2\n#>   review                                                               .classify\n#>   <chr>                                                                    <dbl>\n#> 1 This has been the best TV I've ever used. Great screen, and sound.           1\n#> 2 I regret buying this laptop. It is too slow and the keyboard is too…         2\n#> 3 Not sure how to feel about my new washing machine. Great color, but…         1\n \n# For character vectors, instead of a data frame, use this function \nllm_vec_classify( \n  c(\"this is important!\", \"just whenever\"), \n  c(\"urgent\", \"not urgent\") \n) \n#> [1] \"urgent\" \"urgent\"\n \n# To preview the first call that will be made to the downstream R function \nllm_vec_classify( \n  c(\"this is important!\", \"just whenever\"), \n  c(\"urgent\", \"not urgent\"), \n  preview = TRUE \n) \n#> ollamar::chat(messages = list(list(role = \"user\", content = \"You are a helpful classification engine. Determine if the text refers to one of the following: urgent, not urgent. No capitalization. No explanations.  The answer is based on the following text:\\nthis is important!\")), \n#>     output = \"text\", model = \"llama3.2\", seed = 100)\n```\n:::\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}