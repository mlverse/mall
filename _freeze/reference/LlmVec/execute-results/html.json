{
  "hash": "d14e6fbb48f3ed7d5b6e00d8eff1914e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: LlmVec\n---\n\n\n\n`LlmVec(self, backend='', model='', _cache='_mall_cache', **kwargs)`\n\nClass that adds ability to use an LLM to run batch predictions\n\n\n\n::: {#83f06b2c .cell execution_count=2}\n``` {.python .cell-code}\nfrom chatlas import ChatOllama\nfrom mall import LlmVec\n\nchat = ChatOllama(model = \"llama3.2\")\n\nllm = LlmVec(chat)    \n```\n:::\n\n\n## Methods\n\n| Name | Description |\n| --- | --- |\n| [classify](#mall.LlmVec.classify) | Classify text into specific categories. |\n| [custom](#mall.LlmVec.custom) | Provide the full prompt that the LLM will process. |\n| [extract](#mall.LlmVec.extract) | Pull a specific label from the text. |\n| [sentiment](#mall.LlmVec.sentiment) | Use an LLM to run a sentiment analysis |\n| [summarize](#mall.LlmVec.summarize) | Summarize the text down to a specific number of words. |\n| [translate](#mall.LlmVec.translate) | Translate text into another language. |\n| [verify](#mall.LlmVec.verify) | Check to see if something is true about the text. |\n\n### classify { #mall.LlmVec.classify }\n\n`LlmVec.classify(x, labels='', additional='')`\n\nClassify text into specific categories.\n\n#### Parameters\n\n| Name         | Type   | Description                                                                                                             | Default    |\n|--------------|--------|-------------------------------------------------------------------------------------------------------------------------|------------|\n| `x`          | list   | A list of texts                                                                                                         | _required_ |\n| `labels`     | list   | A list or a DICT object that defines the categories to classify the text as. It will return one of the provided labels. | `''`       |\n| `additional` | str    | Inserts this text into the prompt sent to the LLM                                                                       | `''`       |\n\n#### Examples\n\n::: {#730755cf .cell execution_count=3}\n``` {.python .cell-code}\nllm.classify(['this is important!', 'there is no rush'], ['urgent', 'not urgent'])\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n['urgent', None]\n```\n:::\n:::\n\n\n### custom { #mall.LlmVec.custom }\n\n`LlmVec.custom(x, prompt='', valid_resps='')`\n\nProvide the full prompt that the LLM will process.\n\n#### Parameters\n\n| Name     | Type   | Description                                        | Default    |\n|----------|--------|----------------------------------------------------|------------|\n| `x`      | list   | A list of texts                                    | _required_ |\n| `prompt` | str    | The prompt to send to the LLM along with the `col` | `''`       |\n\n### extract { #mall.LlmVec.extract }\n\n`LlmVec.extract(x, labels='', additional='')`\n\nPull a specific label from the text.\n\n#### Parameters\n\n| Name         | Type   | Description                                                                    | Default    |\n|--------------|--------|--------------------------------------------------------------------------------|------------|\n| `x`          | list   | A list of texts                                                                | _required_ |\n| `labels`     | list   | A list or a DICT object that defines tells the LLM what to look for and return | `''`       |\n| `additional` | str    | Inserts this text into the prompt sent to the LLM                              | `''`       |\n\n#### Examples\n\n::: {#def9cfbf .cell execution_count=4}\n``` {.python .cell-code}\nllm.extract(['bob smith, 123 3rd street'], labels=['name', 'address'])\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n['| bob smith | 123 3rd street |']\n```\n:::\n:::\n\n\n### sentiment { #mall.LlmVec.sentiment }\n\n`LlmVec.sentiment(x, options=['positive', 'negative', 'neutral'], additional='')`\n\nUse an LLM to run a sentiment analysis\n\n#### Parameters\n\n| Name         | Type         | Description                                                    | Default                               |\n|--------------|--------------|----------------------------------------------------------------|---------------------------------------|\n| `x`          | list         | A list of texts                                                | _required_                            |\n| `options`    | list or dict | A list of the sentiment options to use, or a named DICT object | `['positive', 'negative', 'neutral']` |\n| `additional` | str          | Inserts this text into the prompt sent to the LLM              | `''`                                  |\n\n#### Examples\n\n::: {#567dc847 .cell execution_count=5}\n``` {.python .cell-code}\nllm.sentiment(['I am happy', 'I am sad'])\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n['positive', 'negative']\n```\n:::\n:::\n\n\n### summarize { #mall.LlmVec.summarize }\n\n`LlmVec.summarize(x, max_words=10, additional='')`\n\nSummarize the text down to a specific number of words.\n\n#### Parameters\n\n| Name         | Type   | Description                                       | Default    |\n|--------------|--------|---------------------------------------------------|------------|\n| `x`          | list   | A list of texts                                   | _required_ |\n| `max_words`  | int    | Maximum number of words to use for the summary    | `10`       |\n| `additional` | str    | Inserts this text into the prompt sent to the LLM | `''`       |\n\n#### Examples\n\n::: {#9c92779d .cell execution_count=6}\n``` {.python .cell-code}\nllm.summarize(['This has been the best TV Ive ever used. Great screen, and sound.'], max_words = 5)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n['this tv has exceeded expectations']\n```\n:::\n:::\n\n\n### translate { #mall.LlmVec.translate }\n\n`LlmVec.translate(x, language='', additional='')`\n\nTranslate text into another language.\n\n#### Parameters\n\n| Name         | Type   | Description                                                | Default    |\n|--------------|--------|------------------------------------------------------------|------------|\n| `x`          | list   | A list of texts                                            | _required_ |\n| `language`   | str    | The target language to translate to. For example 'French'. | `''`       |\n| `additional` | str    | Inserts this text into the prompt sent to the LLM          | `''`       |\n\n#### Examples\n\n::: {#d41bc3b8 .cell execution_count=7}\n``` {.python .cell-code}\nllm.translate(['This has been the best TV Ive ever used. Great screen, and sound.'], language = 'spanish')\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n['Esto ha sido la mejor televisi√≥n que he tenido, gran pantalla y sonido.']\n```\n:::\n:::\n\n\n### verify { #mall.LlmVec.verify }\n\n`LlmVec.verify(x, what='', yes_no=[1, 0], additional='')`\n\nCheck to see if something is true about the text.\n\n#### Parameters\n\n| Name         | Type   | Description                                                                                                                                                                  | Default    |\n|--------------|--------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------|\n| `x`          | list   | A list of texts                                                                                                                                                              | _required_ |\n| `what`       | str    | The statement or question that needs to be verified against the provided text                                                                                                | `''`       |\n| `yes_no`     | list   | A positional list of size 2, which contains the values to return if true and false. The first position will be used as the 'true' value, and the second as the 'false' value | `[1, 0]`   |\n| `additional` | str    | Inserts this text into the prompt sent to the LLM                                                                                                                            | `''`       |\n\n",
    "supporting": [
      "LlmVec_files"
    ],
    "filters": [],
    "includes": {}
  }
}